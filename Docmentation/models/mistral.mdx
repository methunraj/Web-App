---
title: Mistral
description: Learn how to use Mistral models in Agno.
---

Mistral is a platform for providing endpoints for Large Language models.
See their library of models [here](https://docs.mistral.ai/getting-started/models/models_overview/).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

- `codestral` model is good for code generation and editing.
- `mistral-large-latest` model is good for most use-cases.
- `open-mistral-nemo` is a free model that is good for most use-cases.
- `pixtral-12b-2409` is a vision model that is good for OCR, transcribing documents, and image comparison. It is not always capable at tool calling.

Mistral has tier-based rate limits. See the [docs](https://docs.mistral.ai/deployment/laplateforme/tier/) for more information.

## Authentication

Set your `MISTRAL_API_KEY` environment variable. Get your key from [here](https://console.mistral.ai/api-keys/).

<CodeGroup>

```bash Mac
export MISTRAL_API_KEY=***
```

```bash Windows
setx MISTRAL_API_KEY ***
```

</CodeGroup>

## Example

Use `Mistral` with your `Agent`:

<CodeGroup>

```python agent.py
import os

from agno.agent import Agent, RunResponse
from agno.models.mistral import MistralChat

mistral_api_key = os.getenv("MISTRAL_API_KEY")

agent = Agent(
    model=MistralChat(
        id="mistral-large-latest",
        api_key=mistral_api_key,
    ),
    markdown=True
)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story.")

```

</CodeGroup>

<Note> View more examples [here](../examples/models/mistral). </Note>

## Params

<Snippet file="model-mistral-params.mdx" />

`MistralChat` is a subclass of the [Model](/reference/models/model) class and has access to the same params.
